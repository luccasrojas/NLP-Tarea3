{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multy-Domain Sentiment Dataset: Sentiment Analisys per domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocesamiento\n",
    "Para el preprocesamiento, se creó la clase \"Corpus\" que recibe una serie de documentos y obtiene las etiquetas de cada uno, el vocabulario, y las representaciones tf y tfidf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.sparse import coo_array\n",
    "from lex import senticnet as lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE_LABEL = 1\n",
    "NEGATIVE_LABEL = 0\n",
    "\n",
    "CATEGORY_PATHS = {\n",
    "    \"books\": \"../data/books/\",\n",
    "    \"dvd\": \"../data/dvd/\",\n",
    "    \"electronics\": \"../data/electronics/\",\n",
    "    \"kitchen\": \"../data/kitchen/\",\n",
    "}\n",
    "\n",
    "\n",
    "class Corpus:\n",
    "    # Atributes\n",
    "    __vocabulary = {}\n",
    "    __tf = None\n",
    "    __tfidf = None\n",
    "    __documents = None\n",
    "    __feature_matrix = None\n",
    "    __voc_lst = None\n",
    "    __mood_lst = None\n",
    "\n",
    "\n",
    "    def __init__(self, docs: list, vocabulary: dict = None) -> None:\n",
    "        \"\"\"\n",
    "        Creates the vocabulary, the TF and the TFIDF matricees from docs.\n",
    "        \n",
    "            Params\n",
    "            ------\n",
    "                docs: pd.DataFrame\n",
    "                    List of documents.\n",
    "                \n",
    "                vocabulary: dict | None (default: None)\n",
    "                    A dictionary where the keys are the terms in the vocabulary\n",
    "                    and the values are each term's unique id. If set to None,\n",
    "                    this class will create the vocabulary based on docs.\n",
    "                    WARNING: if specified, vocabulary must contain a \"#UNK#\" key\n",
    "                    for unknown terms.\n",
    "        \"\"\"        \n",
    "        self.__documents = self.__get_docs_df(docs)\n",
    "        if vocabulary is None:\n",
    "            self.__vocabulary, self.__voc_lst = self.__load_vocabulary()\n",
    "        else:\n",
    "            self.__vocabulary = vocabulary\n",
    "            self.__voc_lst = [\"\" for i in range(len(vocabulary))]\n",
    "            for term in vocabulary:\n",
    "                i = vocabulary[term]\n",
    "                self.__voc_lst[i] = term\n",
    "            \n",
    "        self.__tf = self.__load_tf()\n",
    "        self.__tfidf = self.__load_tfidf()\n",
    "        self.__feature_matrix, self.__mood_lst = self.__load_lex_features()\n",
    "\n",
    "    def __get_docs_df(self, docs: list):\n",
    "        \"\"\"\n",
    "        Turns a list of documenst into a pd.DataFrame with \"terms\" and \"labels\"\n",
    "            Params\n",
    "            ------\n",
    "                docs: list\n",
    "                    A list with documents.\n",
    "        \"\"\"\n",
    "        documents = []\n",
    "        for doc in docs:\n",
    "            terms = self.__get_term_counts(doc)\n",
    "            label = self.__get_label(doc)\n",
    "            documents.append([terms, label])\n",
    "        \n",
    "        return pd.DataFrame(documents, columns=[\"terms\", \"label\"])\n",
    "\n",
    "    def __get_term_counts(self, line: str) -> dict:\n",
    "        \"\"\"\n",
    "        Turns a document into a dictionary where keys are terms and values are\n",
    "        the frequencies of those terms.\n",
    "        \"\"\"\n",
    "        line_arr = line.split()\n",
    "        line_arr = line_arr[:-1] # Remove #label#: from the end of array\n",
    "        terms = {}\n",
    "        for term in line_arr:\n",
    "            term_arr = term.split(\":\")\n",
    "            terms[term_arr[0]] = int(term_arr[1])\n",
    "        \n",
    "        return terms\n",
    "    \n",
    "    def __get_label(self, doc: str) -> int:\n",
    "        \"\"\"\n",
    "        Returns the label of a document.\n",
    "        \"\"\"\n",
    "        doc_arr = doc.split()\n",
    "        label_str = doc_arr[-1]\n",
    "        label = label_str.split(\":\")[-1]\n",
    "        if label.lower() == \"negative\":\n",
    "            return NEGATIVE_LABEL\n",
    "        elif label.lower() == \"positive\":\n",
    "            return POSITIVE_LABEL\n",
    "    \n",
    "    def __load_vocabulary(self):\n",
    "        \"\"\"\n",
    "        Extracts the vocabulary from the documents and returns a tuple.\n",
    "        The first entry of the tuple contains a dictionary where keys are\n",
    "        terms of the dictionary and values are a unique id for each term.\n",
    "        The second entry of the tuple contains a list with the vocabylary\n",
    "        organized.\n",
    "        \"\"\"\n",
    "        # Term counts in the whole corpus\n",
    "        voc = {}\n",
    "        voc_lst = []\n",
    "        docs = self.__documents\n",
    "        for i in range(len(docs)):\n",
    "            terms_dict = docs.loc[i, \"terms\"]\n",
    "            for term in terms_dict:\n",
    "                if term in voc:\n",
    "                    voc[term] += terms_dict[term]\n",
    "                else:\n",
    "                    voc[term] = terms_dict[term]\n",
    "        \n",
    "        # Replace terms with one appearance with UNK\n",
    "        terms_to_del = []\n",
    "        for term in voc:\n",
    "            if voc[term] == 1:\n",
    "                terms_to_del.append(term)\n",
    "\n",
    "        # Remove terms that appeare only once\n",
    "        for term in terms_to_del:\n",
    "            voc.pop(term)\n",
    "        \n",
    "        # Assign unique ids to terms in vocabulary\n",
    "        bow = {\"#UNK#\": 0}\n",
    "        voc_lst.append(\"#UNK#\")\n",
    "        i = 1\n",
    "        for term in voc:\n",
    "            voc_lst.append(term)\n",
    "            bow[term] = i\n",
    "            i += 1\n",
    "        \n",
    "        return bow, voc_lst\n",
    "\n",
    "    def __load_tf(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Creates and returns the tf representation of the documents.\n",
    "        \"\"\"\n",
    "        voc = self.__vocabulary\n",
    "        docs = self.__documents\n",
    "        data = []\n",
    "        x = []\n",
    "        y = []\n",
    "        for i in range(len(docs)):\n",
    "            doc = docs.iloc[i]\n",
    "            for term in doc[\"terms\"]:\n",
    "                if term in voc:\n",
    "                    data.append(doc[\"terms\"][term])\n",
    "                    x.append(i)\n",
    "                    y.append(voc[term])\n",
    "                else:\n",
    "                    data.append(doc[\"terms\"][term])\n",
    "                    x.append(i)\n",
    "                    y.append(voc[\"#UNK#\"])\n",
    "        \n",
    "        sparce_matrix = coo_array((data, (x,y)), shape=(len(docs), len(voc)), dtype=np.uint64).tocsr()\n",
    "        return sparce_matrix\n",
    "\n",
    "    def __load_tfidf(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Creates and returns the tf-idf representation of the documents.\n",
    "        \"\"\"\n",
    "        voc = self.__vocabulary\n",
    "        docs = self.__documents\n",
    "        tfs = self.__tf\n",
    "        doc_frec = np.zeros(len(voc))\n",
    "        # Calculate document frequencies\n",
    "        for i in range(len(docs)):\n",
    "            doc = docs.loc[i, \"terms\"]\n",
    "            added_unk = False\n",
    "            for term in doc:\n",
    "                if term in voc:\n",
    "                    term_id = voc[term]\n",
    "                    doc_frec[term_id] += 1\n",
    "                elif not added_unk:\n",
    "                    term_id = voc[\"#UNK#\"]\n",
    "                    doc_frec[term_id] += 1\n",
    "                    added_unk = True\n",
    "\n",
    "        total_docs = len(docs)\n",
    "        data = []\n",
    "        x = []\n",
    "        y = []\n",
    "        for i in range(len(docs)):\n",
    "            doc = docs.iloc[i]\n",
    "            unk_tf = 0\n",
    "            for term in doc[\"terms\"]:\n",
    "                if term in voc:\n",
    "                    term_id = voc[term]\n",
    "                    tf = doc[\"terms\"][term]\n",
    "                    df = int(doc_frec[term_id])\n",
    "                    data.append(math.log10(1+tf) * math.log10(total_docs / df))\n",
    "                    x.append(i)\n",
    "                    y.append(term_id)\n",
    "                else:\n",
    "                    unk_tf += doc[\"terms\"][term]\n",
    "            \n",
    "            # Calculate UNK tfidf\n",
    "            term_id = voc[\"#UNK#\"]\n",
    "            tf = int(tfs[i, term_id])\n",
    "            df = int(doc_frec[term_id])\n",
    "            temp = math.log10(1+tf) * math.log10(total_docs / df)\n",
    "            if temp < 0:\n",
    "                raise Exception(\"HP\")\n",
    "            data.append(math.log10(1+tf) * math.log10(total_docs / df))\n",
    "            x.append(i)\n",
    "            y.append(term_id)\n",
    "\n",
    "        sparce_matrix = coo_array((data, (x, y)), shape=(len(docs), len(voc)), dtype=np.float64).tocsr()        \n",
    "        return sparce_matrix\n",
    "    \n",
    "    def __load_lex_features(self):\n",
    "        \"\"\"\n",
    "        Creates and returns a vector representation of the document using the\n",
    "        followeing features from a lexicon:\n",
    "            - Count of positive words\n",
    "            - Count of negative words\n",
    "            - Count of words with each mood (for example, count of words\n",
    "                whose mood is \"joy\").\n",
    "        \"\"\"\n",
    "        docs = self.__documents\n",
    "\n",
    "        moods = set()\n",
    "        for term in lexicon:\n",
    "            mood = lexicon[term][4]\n",
    "            moods.update([mood])\n",
    "\n",
    "        moods_lst = [\"\" for i in range(len(moods))]\n",
    "        moods_lst.insert(0, \"PWC\")\n",
    "        moods_lst.insert(1, \"NWC\")\n",
    "\n",
    "        moods_dict = {mood: index for index, mood in enumerate(moods)}\n",
    "\n",
    "        for mood in moods_dict:\n",
    "            i = moods_dict[mood] + 2\n",
    "            moods_lst[i] = mood\n",
    "\n",
    "        feature_matrix = np.zeros((len(docs), len(moods) + 2))\n",
    "\n",
    "        for i in range(len(docs)):\n",
    "            doc = docs.loc[i, \"terms\"]\n",
    "            for term in doc:\n",
    "                term_frec = doc[term]\n",
    "                tot_words_in_lex = 0\n",
    "                if term in lexicon:\n",
    "                    tot_words_in_lex += 1\n",
    "                    if lexicon[term][6] == \"positive\":\n",
    "                        feature_matrix[i][0] += term_frec\n",
    "                    else:\n",
    "                        feature_matrix[i][1] += term_frec\n",
    "\n",
    "                    mood = lexicon[term][4]\n",
    "                    mood_id = moods_dict[mood]\n",
    "                    feature_matrix[i][mood_id + 2] += term_frec\n",
    "                else:\n",
    "                    sub_terms = term.split(\"_\")\n",
    "                    for sub_term in sub_terms:\n",
    "                        if sub_term in lexicon:\n",
    "                            tot_words_in_lex += 1\n",
    "                            if lexicon[sub_term][6] == \"positive\":\n",
    "                                feature_matrix[i][0] += term_frec\n",
    "                            else:\n",
    "                                feature_matrix[i][1] += term_frec\n",
    "\n",
    "                            mood = lexicon[sub_term][4]\n",
    "                            mood_id = moods_dict[mood]\n",
    "                            feature_matrix[i][mood_id + 2] += term_frec\n",
    "            \n",
    "        return feature_matrix, moods_lst\n",
    "\n",
    "\n",
    "    def getVocabulary(self) -> dict:\n",
    "        \"\"\"\n",
    "        Returns a dictionary where keys are the terms in the vocabulary\n",
    "        and values are the unique id of those terms.\n",
    "        \"\"\"\n",
    "        return self.__vocabulary\n",
    "    \n",
    "    def getDocuments(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Returns a pandas dataframe where each row represents\n",
    "        a document of the corpus. The dataframe has two columns: terms and\n",
    "        label which represent the terms of the document and its label respectively.\n",
    "        \"\"\"\n",
    "        return self.__documents\n",
    "\n",
    "    def getTfs(self):\n",
    "        \"\"\"\n",
    "        Returns the TF matrix of the corpus.\n",
    "        \"\"\"\n",
    "        return self.__tf\n",
    "    \n",
    "    def getTfidfs(self):\n",
    "        \"\"\"\n",
    "        Returns the TFIDF matrix of the corpus.\n",
    "        \"\"\"\n",
    "        return self.__tfidf\n",
    "    \n",
    "    def getFeatureMatrix(self):\n",
    "        \"\"\"\n",
    "        Returns the feature matrix of the corpus.\n",
    "        \"\"\"\n",
    "        return self.__feature_matrix\n",
    "\n",
    "    def getVocLst(self):\n",
    "        \"\"\"\n",
    "        Returns a list with the vocabulary of the corpus.\n",
    "        \"\"\"\n",
    "        return self.__voc_lst\n",
    "    \n",
    "    def getMoodsLst(self):\n",
    "        \"\"\"\n",
    "        Returns a list where the k-th entry contains the name\n",
    "        of the k-th feature in the feature matrix\n",
    "        \"\"\"\n",
    "        return self.__mood_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Construcción del modelo y métricas por categoría"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(labels: list, predicted_labels: list) -> dict:\n",
    "    \"\"\"\n",
    "    Given the true labels and the predicted labels, calculates and returns\n",
    "    the following metrics inside a dictionary:\n",
    "        - presition\n",
    "        - recall\n",
    "        - f1 score\n",
    "        - accuracy\n",
    "    \"\"\"\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    tn = 0\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        act     = labels[i]\n",
    "        pred    = predicted_labels[i]\n",
    "        if(act == 1 and pred == 1):\n",
    "            tp += 1\n",
    "        elif pred == 1 and act == 0:\n",
    "            fp += 1\n",
    "        elif pred == 0 and act == 1:\n",
    "            fn += 1\n",
    "        elif pred == 0 and act == 0:\n",
    "            tn += 1\n",
    "    \n",
    "    presition = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 =  2 * presition * recall / (presition + recall)\n",
    "    accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "\n",
    "    return {\"presition\": presition, \"recall\": recall, \"f1\": f1, \"accuracy\": accuracy}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def test_nv_classifier(X_train: np.ndarray, y_train, X_test: np.ndarray, y_test) -> dict:\n",
    "    \"\"\"\n",
    "    Given X and y data for training and testing, returns the metrics of a \n",
    "    Multinomial Naive Bays model trained with X and y train data.\n",
    "    \"\"\"\n",
    "    model = MultinomialNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predicted = model.predict(X_test)\n",
    "    return calculate_metrics(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_docs_from_folder_paths(folder_paths: list, test_only = False):\n",
    "    \"\"\"\n",
    "    Given a list of folder_paths, returns a list of train and test\n",
    "    documents, which are extracted from the folder_paths.\n",
    "    \"\"\"\n",
    "    train_docs = []\n",
    "    test_docs = []\n",
    "    for path in folder_paths:\n",
    "        positive_path = os.path.join(path, \"positive.review\")\n",
    "        negative_path = os.path.join(path, \"negative.review\")\n",
    "        test_path = os.path.join(path, \"unlabeled.review\")\n",
    "\n",
    "        f = open(test_path)\n",
    "        line = f.readline()\n",
    "        while line != \"\":\n",
    "            test_docs.append(line)\n",
    "            line = f.readline()\n",
    "        f.close()\n",
    "\n",
    "        if test_only:\n",
    "            return test_docs\n",
    "\n",
    "        f = open(positive_path)\n",
    "        line = f.readline()\n",
    "        while line != \"\":\n",
    "            train_docs.append(line)\n",
    "            line = f.readline()\n",
    "        f.close()\n",
    "\n",
    "        f = open(negative_path)\n",
    "        line = f.readline()\n",
    "        while line != \"\":\n",
    "            train_docs.append(line)\n",
    "            line = f.readline()\n",
    "        f.close()\n",
    "\n",
    "    return train_docs, test_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "def test_lr_classifier(X_train: np.ndarray, y_train, X_test: np.ndarray, y_test, \\\n",
    "                        penalty = None, solver = \"lbfgs\", max_iter = 100) -> dict:\n",
    "    \"\"\"\n",
    "    Given X and y data for training and testing, returns the metrics of a \n",
    "    Logistic Regresion model trained with X and y train data. Refer to\n",
    "    LogisticRegresion sklearn documentation for information on\n",
    "    \"penalty\", \"solver\" and \"max_iter\" parameters.\n",
    "    \"\"\"\n",
    "    model = LogisticRegression(penalty=penalty, solver=solver, max_iter=max_iter)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predicted = model.predict(X_test)\n",
    "    return calculate_metrics(y_test, y_predicted), model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(metrics: dict, end=None):\n",
    "    print(metrics[\"presition\"], metrics[\"recall\"], metrics[\"f1\"],\\\n",
    "          metrics[\"accuracy\"], sep=\";\", end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_weights(weights, map):\n",
    "    weights = list(enumerate(weights[0, :]))\n",
    "    weights = sorted(weights, key=lambda x: abs(x[1]), reverse=True)[0:5]\n",
    "    print(\"WEIGHTS:\", end=\"\")\n",
    "    for weight in weights:\n",
    "        i = weight[0]\n",
    "        label = map[i]\n",
    "        print(label, \": \", abs(weight[1]), sep=\"\", end=\";\")\n",
    "    \n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_by_cat():\n",
    "    \"\"\"\n",
    "    Builds and tests models for all four cathegories using the following\n",
    "    vector representation of the documents:\n",
    "        - Tf\n",
    "        - Tfidf\n",
    "        - Feature matrix\n",
    "    Results are printed.\n",
    "    \"\"\"\n",
    "    for cat in CATEGORY_PATHS:\n",
    "        # === MULTINOMIAL NV ===\n",
    "        print(\"=== Test for:\", cat, \"===\")\n",
    "        folder_path = CATEGORY_PATHS[cat]\n",
    "        train_docs, test_docs = get_docs_from_folder_paths([folder_path])\n",
    "        train_corpus = Corpus(train_docs)\n",
    "        test_corpus = Corpus(test_docs, train_corpus.getVocabulary())\n",
    "        y_train = train_corpus.getDocuments()[\"label\"]\n",
    "        y_test = test_corpus.getDocuments()[\"label\"]\n",
    "\n",
    "        # Test with TFs\n",
    "        print(\"TFs: \", end=\"\")\n",
    "        X_train = train_corpus.getTfs()\n",
    "        X_test = test_corpus.getTfs()\n",
    "        print(test_nv_classifier(X_train, y_train, X_test, y_test))\n",
    "        # print_metrics(test_nv_classifier(X_train, y_train, X_test, y_test), end=\";\")\n",
    "\n",
    "        # Test with TFIDFs\n",
    "        print(\"TFIDFs: \", end=\"\")\n",
    "        X_train = train_corpus.getTfidfs()\n",
    "        X_test = test_corpus.getTfidfs()\n",
    "        print(test_nv_classifier(X_train, y_train, X_test, y_test))\n",
    "        # print_metrics(test_nv_classifier(X_train, y_train, X_test, y_test), end=\";\")\n",
    "\n",
    "\n",
    "        # Test with feature matrix\n",
    "        print(\"Feature matrix: \", end=\"\")\n",
    "        X_train = train_corpus.getFeatureMatrix()\n",
    "        X_test = test_corpus.getFeatureMatrix()\n",
    "        print(test_nv_classifier(X_train, y_train, X_test, y_test))\n",
    "        # print_metrics(test_nv_classifier(X_train, y_train, X_test, y_test), end=\";\")\n",
    "\n",
    "\n",
    "        # print(\"\")\n",
    "\n",
    "        # === LR ===\n",
    "        print(\"=== LR for:\", cat, \"===\")\n",
    "        # Test with TFs\n",
    "        print(\"TFs: \", end=\"\")\n",
    "        X_train = train_corpus.getTfs().toarray()\n",
    "        X_test = test_corpus.getTfs()\n",
    "        metrics, weights = test_lr_classifier(X_train, y_train, X_test, y_test, max_iter=4000)\n",
    "        print(metrics)\n",
    "        print_weights(weights, train_corpus.getVocLst())\n",
    "        # print_metrics(test_lr_classifier(X_train, y_train, X_test, y_test, max_iter=4000), end=\";\")\n",
    "\n",
    "\n",
    "        # Test with TFIDFs\n",
    "        print(\"TFIDFs: \", end=\"\")\n",
    "        X_train = train_corpus.getTfidfs().toarray()\n",
    "        X_test = test_corpus.getTfidfs()\n",
    "        metrics, weights = test_lr_classifier(X_train, y_train, X_test, y_test)\n",
    "        print(metrics)\n",
    "        print_weights(weights, train_corpus.getVocLst())\n",
    "        # print_metrics(test_lr_classifier(X_train, y_train, X_test, y_test), end=\";\")\n",
    "\n",
    "\n",
    "        # Test with feature matrix\n",
    "        print(\"Feature matrix: \", end=\"\")\n",
    "        X_train = train_corpus.getFeatureMatrix()\n",
    "        X_test = test_corpus.getFeatureMatrix()\n",
    "        metrics, weights = test_lr_classifier(X_train, y_train, X_test, y_test, max_iter=4000)\n",
    "        print(metrics)\n",
    "        print_weights(weights, train_corpus.getMoodsLst())\n",
    "        # print_metrics(test_lr_classifier(X_train, y_train, X_test, y_test, max_iter=4000), end=\";\")\n",
    "\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test for: books ===\n",
      "TFs: {'presition': 0.8158333333333333, 'recall': 0.8648409893992933, 'f1': 0.8396226415094339, 'accuracy': 0.832474804031355}\n",
      "TFIDFs: {'presition': 0.827893175074184, 'recall': 0.8626325088339223, 'f1': 0.8449059052563271, 'accuracy': 0.839417693169093}\n",
      "Feature matrix: {'presition': 0.6186172616357886, 'recall': 0.6046819787985865, 'f1': 0.6115702479338844, 'accuracy': 0.6105263157894737}\n",
      "=== LR for: books ===\n",
      "TFs: {'presition': 0.7816091954022989, 'recall': 0.8710247349823321, 'f1': 0.823898057238354, 'accuracy': 0.8111982082866741}\n",
      "WEIGHTS:excellent: 37.24507250183929;bad: 31.587808695050633;boring: 26.352893753232596;disappointing: 22.9574894592133;easy: 22.57896255079269;\n",
      "TFIDFs: {'presition': 0.8695848375451264, 'recall': 0.851148409893993, 'f1': 0.8602678571428571, 'accuracy': 0.8597984322508399}\n",
      "WEIGHTS:excellent: 8.236708564381647;bad: 7.636252900271601;great: 7.102789921222948;waste: 6.711613188045029;boring: 6.650839822384189;\n",
      "Feature matrix: {'presition': 0.6093620546810273, 'recall': 0.6497349823321554, 'f1': 0.628901239846088, 'accuracy': 0.6111982082866741}\n",
      "WEIGHTS:NWC: 0.08121010311594144;#fear: 0.07761783948534967;#surprise: 0.07358067621054588;PWC: 0.07242521824687798;#interest: 0.07028953001374463;\n",
      "\n",
      "=== Test for: dvd ===\n",
      "TFs: {'presition': 0.7673860911270983, 'recall': 0.8854454897620365, 'f1': 0.8221993833504625, 'accuracy': 0.8070273284997211}\n",
      "TFIDFs: {'presition': 0.797514241325738, 'recall': 0.8522412838959601, 'f1': 0.8239700374531835, 'accuracy': 0.8165086447295036}\n",
      "Feature matrix: {'presition': 0.6283505154639175, 'recall': 0.6745987825124515, 'f1': 0.6506538564184681, 'accuracy': 0.6349693251533742}\n",
      "=== LR for: dvd ===\n",
      "TFs: {'presition': 0.7798582995951417, 'recall': 0.8527946873270614, 'f1': 0.8146973301612477, 'accuracy': 0.8045175683212493}\n",
      "WEIGHTS:bad: 34.795827463631184;worst: 30.26038602309544;boring: 27.55782064744805;excellent: 24.436996896916384;terrible: 22.682889045089276;\n",
      "TFIDFs: {'presition': 0.8128772635814889, 'recall': 0.8942999446596569, 'f1': 0.8516469038208168, 'accuracy': 0.8430005577244841}\n",
      "WEIGHTS:bad: 10.128762316052198;great: 9.352001142078404;excellent: 8.62279590396393;worst: 8.473885776860904;best: 8.134302670289275;\n",
      "Feature matrix: {'presition': 0.6402582159624414, 'recall': 0.6037631433314886, 'f1': 0.6214753631444033, 'accuracy': 0.6293920803123257}\n",
      "WEIGHTS:#sadness: 0.05566773438221077;#anger: 0.04035480748366201;#joy: 0.03935558109399382;#surprise: 0.02557125744877282;#fear: 0.023631427429171008;\n",
      "\n",
      "=== Test for: electronics ===\n",
      "TFs: {'presition': 0.8196090996475489, 'recall': 0.8953447672383619, 'f1': 0.8558046169287387, 'accuracy': 0.8482661503256469}\n",
      "TFIDFs: {'presition': 0.8348961821835231, 'recall': 0.8725936296814841, 'f1': 0.8533287694677393, 'accuracy': 0.8491462770638972}\n",
      "Feature matrix: {'presition': 0.6302631578947369, 'recall': 0.6706335316765838, 'f1': 0.649821943361031, 'accuracy': 0.6365076571026228}\n",
      "=== LR for: electronics ===\n",
      "TFs: {'presition': 0.858093903293623, 'recall': 0.8571928596429822, 'f1': 0.8576431448082646, 'accuracy': 0.8568913923604999}\n",
      "WEIGHTS:excellent: 27.669569217424716;poor: 22.950908252250244;perfect: 21.722237595524835;bad: 18.068549446478187;great: 17.83453627024335;\n",
      "TFIDFs: {'presition': 0.8880840275262586, 'recall': 0.8582429121456073, 'f1': 0.8729085083659665, 'accuracy': 0.8743179017778561}\n",
      "WEIGHTS:great: 12.691660549075728;excellent: 9.280402588950151;not: 8.301124102201921;price: 8.151685277099224;perfect: 7.680514404547148;\n",
      "Feature matrix: {'presition': 0.629735752944922, 'recall': 0.6923346167308365, 'f1': 0.6595531843947983, 'accuracy': 0.6405562400985741}\n",
      "WEIGHTS:#disgust: 0.31014861655449066;#admiration: 0.14406388138122192;#joy: 0.14013195745455584;#interest: 0.12509322105362433;#surprise: 0.1218167470974441;\n",
      "\n",
      "=== Test for: kitchen ===\n",
      "TFs: {'presition': 0.866996699669967, 'recall': 0.8893026404874746, 'f1': 0.8780080213903744, 'accuracy': 0.8772077375946173}\n",
      "TFIDFs: {'presition': 0.8678045515394913, 'recall': 0.8777928232904536, 'f1': 0.8727701110737126, 'accuracy': 0.872834314550042}\n",
      "Feature matrix: {'presition': 0.635036496350365, 'recall': 0.6773865944482058, 'f1': 0.6555282555282554, 'accuracy': 0.6462573591253153}\n",
      "=== LR for: kitchen ===\n",
      "TFs: {'presition': 0.8520077720207254, 'recall': 0.8906567366283006, 'f1': 0.8709036742800398, 'accuracy': 0.8687973086627419}\n",
      "WEIGHTS:easy: 25.9247280402957;great: 20.874247722981192;perfect: 20.855828685586314;excellent: 20.009446238280287;best: 19.6156048549694;\n",
      "TFIDFs: {'presition': 0.8760169215750081, 'recall': 0.9113067027758971, 'f1': 0.8933134229301476, 'accuracy': 0.8918418839360808}\n",
      "WEIGHTS:great: 13.442093667155348;easy: 10.953074627657205;not: 10.036900004015322;love: 9.412528464676344;easy_to: 9.380555858239148;\n",
      "Feature matrix: {'presition': 0.6388712745719721, 'recall': 0.6821259309410969, 'f1': 0.6597904387688278, 'accuracy': 0.6504625735912531}\n",
      "WEIGHTS:#disgust: 0.2716119571527937;NWC: 0.06970892112575819;#admiration: 0.06248748340610725;#anger: 0.043771597780737914;#fear: 0.03327450997862672;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_by_cat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Construcción del modelo y métricas con un compilado de todas las categorías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_complete():\n",
    "    \"\"\"\n",
    "    Compiles a unified corpus using all the documents from all the cathegories.\n",
    "    Then, builds and tests models for all four cathegories using the following\n",
    "    vector representation of the documents:\n",
    "        - Tf\n",
    "        - Tfidf\n",
    "        - Feature matrix\n",
    "    Results are printed.\n",
    "    \"\"\"\n",
    "    folder_paths = []\n",
    "    for cat in CATEGORY_PATHS:\n",
    "        folder_paths.append(CATEGORY_PATHS[cat])\n",
    "\n",
    "    train_docs, test_docs = get_docs_from_folder_paths(folder_paths)\n",
    "    train_corpus = Corpus(train_docs)\n",
    "    y_train = train_corpus.getDocuments()[\"label\"]\n",
    "\n",
    "    printed_weights = 0\n",
    "    for cat in CATEGORY_PATHS:\n",
    "        print(\"Testing for\", cat)\n",
    "        path = CATEGORY_PATHS[cat]\n",
    "        test_docs = get_docs_from_folder_paths([path], test_only=True)\n",
    "        test_corpus = Corpus(test_docs, train_corpus.getVocabulary())\n",
    "        y_test = test_corpus.getDocuments()[\"label\"]\n",
    "\n",
    "        # === NV ===\n",
    "        print(\"NV\")\n",
    "        # TFs\n",
    "        print(\"TFs: \", end=\"\")\n",
    "        X_train = train_corpus.getTfs()\n",
    "        X_test = test_corpus.getTfs()\n",
    "        print(test_nv_classifier(X_train, y_train, X_test, y_test))\n",
    "        # print_metrics(test_nv_classifier(X_train, y_train, X_test, y_test), end=\";\")\n",
    "\n",
    "        # Test with TFIDFs\n",
    "        print(\"TFIDFs: \", end=\"\")\n",
    "        X_train = train_corpus.getTfidfs()\n",
    "        X_test = test_corpus.getTfidfs()\n",
    "        print(test_nv_classifier(X_train, y_train, X_test, y_test))\n",
    "        # print_metrics(test_nv_classifier(X_train, y_train, X_test, y_test), end=\";\")\n",
    "\n",
    "        # Test with feature matrix\n",
    "        print(\"Feature matrix:\", end=\"\")\n",
    "        X_train = train_corpus.getFeatureMatrix()\n",
    "        X_test = test_corpus.getFeatureMatrix()\n",
    "        print(test_nv_classifier(X_train, y_train, X_test, y_test))\n",
    "        # print_metrics(test_nv_classifier(X_train, y_train, X_test, y_test), end=\";\")\n",
    "\n",
    "        # print()\n",
    "\n",
    "        # === LR ===\n",
    "        print(\"LR\")\n",
    "        # TFs\n",
    "        print(\"TFs: \", end=\"\")\n",
    "        X_train = train_corpus.getTfs()\n",
    "        X_test = test_corpus.getTfs()\n",
    "        metrics, weights = test_lr_classifier(X_train, y_train, X_test, y_test, max_iter=4000)\n",
    "        print(metrics)\n",
    "        if printed_weights < 3:\n",
    "            print_weights(weights, train_corpus.getVocLst())\n",
    "            printed_weights += 1\n",
    "        # print_metrics(test_lr_classifier(X_train, y_train, X_test, y_test, max_iter=4000), end=\";\")\n",
    "\n",
    "        # Test with TFIDFs\n",
    "        print(\"TFIDFs: \", end=\"\")\n",
    "        X_train = train_corpus.getTfidfs()\n",
    "        X_test = test_corpus.getTfidfs()\n",
    "        metrics, weights = test_lr_classifier(X_train, y_train, X_test, y_test)\n",
    "        print(metrics)\n",
    "        if printed_weights < 3:\n",
    "            print_weights(weights, train_corpus.getVocLst())\n",
    "            printed_weights += 1\n",
    "        # print_metrics(test_lr_classifier(X_train, y_train, X_test, y_test), end=\";\")\n",
    "\n",
    "\n",
    "        # Test with feature matrix\n",
    "        print(\"Feature matrix:\", end=\"\")\n",
    "        X_train = train_corpus.getFeatureMatrix()\n",
    "        X_test = test_corpus.getFeatureMatrix()\n",
    "        metrics, weights = test_lr_classifier(X_train, y_train, X_test, y_test, max_iter=4000)\n",
    "        print(metrics)\n",
    "        if printed_weights < 3:\n",
    "            print_weights(weights, train_corpus.getMoodsLst())\n",
    "            printed_weights += 1\n",
    "        # print_metrics(test_lr_classifier(X_train, y_train, X_test, y_test, max_iter=4000), end=\";\")\n",
    "\n",
    "\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for books\n",
      "NV\n",
      "TFs: {'presition': 0.7981438515081206, 'recall': 0.911660777385159, 'f1': 0.8511340206185567, 'accuracy': 0.8382978723404255}\n",
      "TFIDFs: {'presition': 0.8163841807909604, 'recall': 0.8935512367491166, 'f1': 0.8532264867144665, 'accuracy': 0.844120940649496}\n",
      "Feature matrix:{'presition': 0.6261930010604454, 'recall': 0.5216431095406361, 'f1': 0.5691566265060242, 'accuracy': 0.5995520716685331}\n",
      "LR\n",
      "TFs: {'presition': 0.8279248505550811, 'recall': 0.8564487632508834, 'f1': 0.8419452887537994, 'accuracy': 0.8369540873460246}\n",
      "WEIGHTS:excellent: 76.02172434422741;disappointing: 64.37684487765047;waste: 61.127173477835825;boring: 59.566383395697635;terrible: 55.16151092296514;\n",
      "TFIDFs: {'presition': 0.8689105403011514, 'recall': 0.8666077738515902, 'f1': 0.8677576293675365, 'accuracy': 0.8660694288913774}\n",
      "WEIGHTS:great: 20.3351464280531;excellent: 17.55605045493851;not: 16.279194895570335;bad: 14.31918989044432;waste: 13.788237297348847;\n",
      "Feature matrix:{'presition': 0.6388564760793466, 'recall': 0.4836572438162544, 'f1': 0.55052790346908, 'accuracy': 0.5995520716685331}\n",
      "WEIGHTS:NWC: 0.020980132708259852;#sadness: 0.019276288855826447;#disgust: 0.013010132415077837;#joy: 0.011815187897285096;#fear: 0.00854033764071006;\n",
      "\n",
      "Testing for dvd\n",
      "NV\n",
      "TFs: {'presition': 0.7984344422700587, 'recall': 0.9031543995572773, 'f1': 0.8475720592054012, 'accuracy': 0.8363078639152258}\n",
      "TFIDFs: {'presition': 0.8283464566929134, 'recall': 0.8732706142778085, 'f1': 0.8502155172413793, 'accuracy': 0.8449525934188511}\n",
      "Feature matrix:{'presition': 0.6217792902284881, 'recall': 0.707802988378528, 'f1': 0.662008281573499, 'accuracy': 0.6358059118795315}\n",
      "LR\n",
      "TFs: {'presition': 0.8247796785899429, 'recall': 0.8804648588821251, 'f1': 0.851713062098501, 'accuracy': 0.8455103179029559}\n",
      "TFIDFs: {'presition': 0.8705035971223022, 'recall': 0.8705035971223022, 'f1': 0.8705035971223022, 'accuracy': 0.8694924707194646}\n",
      "Feature matrix:{'presition': 0.6160458452722063, 'recall': 0.7138904261206419, 'f1': 0.6613688797744168, 'accuracy': 0.6316229782487451}\n",
      "\n",
      "Testing for electronics\n",
      "NV\n",
      "TFs: {'presition': 0.8879699248120301, 'recall': 0.8267413370668534, 'f1': 0.8562624614826899, 'accuracy': 0.8604118993135011}\n",
      "TFIDFs: {'presition': 0.8920278637770898, 'recall': 0.8067903395169759, 'f1': 0.8472707222936959, 'accuracy': 0.8537229361027988}\n",
      "Feature matrix:{'presition': 0.6109286354135562, 'recall': 0.7161358067903395, 'f1': 0.6593619078311311, 'accuracy': 0.6278824150677698}\n",
      "LR\n",
      "TFs: {'presition': 0.8839957035445757, 'recall': 0.8641932096604831, 'f1': 0.8739823008849558, 'accuracy': 0.8746699524731562}\n",
      "TFIDFs: {'presition': 0.9135667396061269, 'recall': 0.8767938396919845, 'f1': 0.8948026433291659, 'accuracy': 0.8963210702341137}\n",
      "Feature matrix:{'presition': 0.6106750392464678, 'recall': 0.6807840392019601, 'f1': 0.6438265475008275, 'accuracy': 0.6211934518570674}\n",
      "\n",
      "Testing for kitchen\n",
      "NV\n",
      "TFs: {'presition': 0.8802816901408451, 'recall': 0.8886255924170616, 'f1': 0.8844339622641509, 'accuracy': 0.8846089150546678}\n",
      "TFIDFs: {'presition': 0.8876021798365122, 'recall': 0.8821936357481381, 'f1': 0.8848896434634975, 'accuracy': 0.8859545836837679}\n",
      "Feature matrix:{'presition': 0.626253418413856, 'recall': 0.6976980365605958, 'f1': 0.6600480384307446, 'accuracy': 0.6428931875525652}\n",
      "LR\n",
      "TFs: {'presition': 0.8833389205497821, 'recall': 0.8920108327691266, 'f1': 0.8876536971534444, 'accuracy': 0.8878048780487805}\n",
      "TFIDFs: {'presition': 0.9129979035639413, 'recall': 0.8845633039945836, 'f1': 0.8985557083906465, 'accuracy': 0.9007569386038689}\n",
      "Feature matrix:{'presition': 0.6262224938875306, 'recall': 0.6936357481381178, 'f1': 0.6582075168647606, 'accuracy': 0.6420521446593777}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_complete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
